# ì˜¤ë˜ëœ ë‰´ìŠ¤ ë°ì´í„° ì •ë¦¬ - êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” Cloud Functionì„ ì‚¬ìš©í•œ ì˜¤ë˜ëœ ë‰´ìŠ¤ ë°ì´í„° ìë™ ì •ë¦¬ ì‹œìŠ¤í…œì˜ êµ¬í˜„ ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ¯ êµ¬í˜„ ëª©í‘œ

- **ë³´ê´€ ê¸°ê°„**: 30ì¼
- **ì •ë¦¬ ì£¼ê¸°**: ë§¤ì›” 1ì¼ ìƒˆë²½ 3ì‹œ (KST)
- **ëŒ€ìƒ**: ëª¨ë“  ì‚¬ìš©ìì˜ summaries ë°ì´í„°
- **ë°©ì‹**: Cloud Function + Cloud Scheduler + Pub/Sub

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
GCPNewsPortal/
â”œâ”€â”€ backend/
â”œâ”€â”€ news_summarizer/
â”œâ”€â”€ cleanup_function/          # â† ìƒˆë¡œ ìƒì„±
â”‚   â”œâ”€â”€ main.py               # Cloud Function ì½”ë“œ
â”‚   â”œâ”€â”€ requirements.txt      # ì˜ì¡´ì„±
â”‚   â””â”€â”€ .gcloudignore        # ë°°í¬ ì œì™¸ íŒŒì¼
â””â”€â”€ docs/
    â””â”€â”€ cleanup-implementation-guide.md
```

## ğŸš€ êµ¬í˜„ ë‹¨ê³„

### Step 1: cleanup_function ë””ë ‰í† ë¦¬ ìƒì„±

```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ
mkdir cleanup_function
cd cleanup_function
```

### Step 2: main.py ì‘ì„±

`cleanup_function/main.py` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤:

```python
"""
Cloud Function for cleaning up old news summaries
Triggered by Pub/Sub message from Cloud Scheduler
"""

import functions_framework
from google.cloud import firestore
from datetime import datetime, timedelta
import base64
import json
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@functions_framework.cloud_event
def cleanup_old_summaries(cloud_event):
    """
    30ì¼ ì´ìƒ ëœ ë‰´ìŠ¤ ìš”ì•½ì„ ì‚­ì œí•˜ëŠ” Cloud Function

    Args:
        cloud_event: Pub/Sub ì´ë²¤íŠ¸ ê°ì²´

    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ (ì‚¬ìš©ì ìˆ˜, ì‚­ì œëœ ë¬¸ì„œ ìˆ˜, ê¸°ì¤€ ë‚ ì§œ)
    """

    try:
        logger.info("=== Cleanup job started ===")

        # Firestore í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        db = firestore.Client()

        # ë³´ê´€ ê¸°ê°„ ì„¤ì • (ê¸°ë³¸ê°’: 30ì¼)
        retention_days = 30

        # Pub/Sub ë©”ì‹œì§€ì—ì„œ ì„¤ì •ê°’ ì½ê¸° (ì„ íƒì‚¬í•­)
        if cloud_event.data and "message" in cloud_event.data:
            try:
                message_data = base64.b64decode(
                    cloud_event.data["message"]["data"]
                ).decode()
                config = json.loads(message_data)
                retention_days = config.get('retention_days', 30)
                logger.info(f"Retention days from message: {retention_days}")
            except Exception as e:
                logger.warning(f"Failed to parse message data, using default: {e}")

        # ì‚­ì œ ê¸°ì¤€ ë‚ ì§œ ê³„ì‚°
        cutoff_date = datetime.utcnow() - timedelta(days=retention_days)
        cutoff_iso = cutoff_date.isoformat()

        logger.info(f"Cutoff date: {cutoff_iso} (retention: {retention_days} days)")

        total_deleted = 0
        users_processed = 0
        users_with_deletions = 0

        # ëª¨ë“  ì‚¬ìš©ì ìˆœíšŒ
        users_ref = db.collection('users')
        users = users_ref.stream()

        for user_doc in users:
            user_id = user_doc.id
            users_processed += 1

            logger.info(f"Processing user: {user_id}")

            # í•´ë‹¹ ì‚¬ìš©ìì˜ ì˜¤ë˜ëœ summaries ì¡°íšŒ
            old_summaries = (
                db.collection('users')
                .document(user_id)
                .collection('summaries')
                .where('created_at', '<', cutoff_iso)
                .stream()
            )

            # ë°°ì¹˜ ì‚­ì œ (Firestore ë°°ì¹˜ëŠ” ìµœëŒ€ 500ê°œ ì œí•œ)
            batch = db.batch()
            batch_count = 0
            user_deleted = 0

            for doc in old_summaries:
                batch.delete(doc.reference)
                batch_count += 1
                user_deleted += 1

                # 500ê°œë§ˆë‹¤ ì»¤ë°‹
                if batch_count >= 500:
                    batch.commit()
                    total_deleted += batch_count
                    logger.info(f"Batch committed: {batch_count} documents")
                    batch = db.batch()
                    batch_count = 0

            # ë‚¨ì€ ë¬¸ì„œ ì»¤ë°‹
            if batch_count > 0:
                batch.commit()
                total_deleted += batch_count
                logger.info(f"Final batch committed: {batch_count} documents")

            if user_deleted > 0:
                users_with_deletions += 1
                logger.info(f"User {user_id}: deleted {user_deleted} old summaries")

        # ê²°ê³¼ ë¡œê¹…
        result = {
            'status': 'success',
            'users_processed': users_processed,
            'users_with_deletions': users_with_deletions,
            'total_deleted': total_deleted,
            'cutoff_date': cutoff_iso,
            'retention_days': retention_days
        }

        logger.info(f"=== Cleanup job completed ===")
        logger.info(f"Summary: {result}")

        return result

    except Exception as e:
        logger.error(f"Error during cleanup: {str(e)}", exc_info=True)
        return {
            'status': 'error',
            'error': str(e)
        }
```

### Step 3: requirements.txt ì‘ì„±

`cleanup_function/requirements.txt` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```txt
functions-framework==3.*
google-cloud-firestore==2.*
```

### Step 4: .gcloudignore ì‘ì„±

`cleanup_function/.gcloudignore` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```
.gcloudignore
.git
.gitignore
__pycache__/
*.pyc
*.pyo
*.pyd
.pytest_cache/
.coverage
htmlcov/
venv/
```

### Step 5: GCP ë¦¬ì†ŒìŠ¤ ìƒì„±

#### 5-1. Pub/Sub Topic ìƒì„±

```bash
gcloud pubsub topics create cleanup-old-news-topic \
  --project=YOUR_PROJECT_ID
```

**í™•ì¸:**
```bash
gcloud pubsub topics list
```

#### 5-2. Cloud Function ë°°í¬

```bash
# cleanup_function ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
cd cleanup_function

gcloud functions deploy cleanup-old-news \
  --gen2 \
  --runtime=python311 \
  --region=asia-northeast3 \
  --source=. \
  --entry-point=cleanup_old_summaries \
  --trigger-topic=cleanup-old-news-topic \
  --memory=256MB \
  --timeout=540s \
  --set-env-vars GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID
```

**íŒŒë¼ë¯¸í„° ì„¤ëª…:**
- `--gen2`: Cloud Functions 2ì„¸ëŒ€ ì‚¬ìš©
- `--runtime=python311`: Python 3.11 ëŸ°íƒ€ì„
- `--region=asia-northeast3`: ì„œìš¸ ë¦¬ì „
- `--source=.`: í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ì½”ë“œ ë°°í¬
- `--entry-point=cleanup_old_summaries`: ì‹¤í–‰í•  í•¨ìˆ˜ ì´ë¦„
- `--trigger-topic`: Pub/Sub íŠ¸ë¦¬ê±° ì„¤ì •
- `--memory=256MB`: ë©”ëª¨ë¦¬ í• ë‹¹ (í•„ìš”ì‹œ 512MBë¡œ ì¦ì„¤)
- `--timeout=540s`: íƒ€ì„ì•„ì›ƒ 9ë¶„ (ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„)

**ë°°í¬ í™•ì¸:**
```bash
gcloud functions describe cleanup-old-news \
  --region=asia-northeast3 \
  --gen2
```

#### 5-3. Cloud Scheduler Job ìƒì„±

```bash
gcloud scheduler jobs create pubsub cleanup-old-news-job \
  --location=asia-northeast3 \
  --schedule="0 3 1 * *" \
  --time-zone="Asia/Seoul" \
  --topic=cleanup-old-news-topic \
  --message-body='{"retention_days": 30}'
```

**íŒŒë¼ë¯¸í„° ì„¤ëª…:**
- `--schedule="0 3 1 * *"`: ë§¤ì›” 1ì¼ ìƒˆë²½ 3ì‹œ ì‹¤í–‰ (Cron í‘œí˜„ì‹)
- `--time-zone="Asia/Seoul"`: í•œêµ­ ì‹œê°„ ê¸°ì¤€
- `--topic`: ë°œí–‰í•  Pub/Sub Topic
- `--message-body`: Functionì— ì „ë‹¬í•  ì„¤ì • (JSON)

**ìŠ¤ì¼€ì¤„ í‘œí˜„ì‹ ì˜ˆì‹œ:**
```
0 3 1 * *      â†’ ë§¤ì›” 1ì¼ 03:00
0 3 1,15 * *   â†’ ë§¤ì›” 1ì¼, 15ì¼ 03:00
0 3 * * 0      â†’ ë§¤ì£¼ ì¼ìš”ì¼ 03:00
0 3 * * *      â†’ ë§¤ì¼ 03:00
```

**Job í™•ì¸:**
```bash
gcloud scheduler jobs list --location=asia-northeast3
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë¡œì»¬ í…ŒìŠ¤íŠ¸ (Functions Framework)

```bash
# cleanup_function ë””ë ‰í† ë¦¬ì—ì„œ
pip install -r requirements.txt
pip install functions-framework

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/service-account-key.json"
export GOOGLE_CLOUD_PROJECT="your-project-id"

# ë¡œì»¬ ì‹¤í–‰
functions-framework --target=cleanup_old_summaries --debug
```

**í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ë°œí–‰:**
```bash
# ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ
curl -X POST http://localhost:8080 \
  -H "Content-Type: application/json" \
  -d '{
    "data": {
      "message": {
        "data": "'$(echo -n '{"retention_days": 30}' | base64)'"
      }
    }
  }'
```

### ë°°í¬ í›„ ìˆ˜ë™ í…ŒìŠ¤íŠ¸

```bash
# Scheduler Job ì¦‰ì‹œ ì‹¤í–‰
gcloud scheduler jobs run cleanup-old-news-job \
  --location=asia-northeast3
```

**ë˜ëŠ” Pub/Subë¡œ ì§ì ‘ ë©”ì‹œì§€ ë°œí–‰:**
```bash
gcloud pubsub topics publish cleanup-old-news-topic \
  --message='{"retention_days": 30}'
```

### ë¡œê·¸ í™•ì¸

```bash
# Cloud Function ë¡œê·¸ ì‹¤ì‹œê°„ ë³´ê¸°
gcloud functions logs read cleanup-old-news \
  --region=asia-northeast3 \
  --gen2 \
  --limit=50
```

**ë˜ëŠ” Cloud Consoleì—ì„œ:**
1. GCP Console â†’ Logging â†’ Logs Explorer
2. ì¿¼ë¦¬ ì…ë ¥:
```
resource.type="cloud_function"
resource.labels.function_name="cleanup-old-news"
severity>=INFO
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### Cloud Logging ì¿¼ë¦¬ ì˜ˆì‹œ

**ì„±ê³µì ì¸ ì‹¤í–‰ í™•ì¸:**
```
resource.type="cloud_function"
resource.labels.function_name="cleanup-old-news"
jsonPayload.message=~"Cleanup job completed"
```

**ì—ëŸ¬ í™•ì¸:**
```
resource.type="cloud_function"
resource.labels.function_name="cleanup-old-news"
severity>=ERROR
```

**ì‚­ì œëœ ë¬¸ì„œ ìˆ˜ í™•ì¸:**
```
resource.type="cloud_function"
resource.labels.function_name="cleanup-old-news"
jsonPayload.message=~"total_deleted"
```

### ì•Œë¦¼ ì„¤ì • (ì„ íƒì‚¬í•­)

ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ì„ ë°›ìœ¼ë ¤ë©´:

1. **Alerting Policy ìƒì„±**
   - GCP Console â†’ Monitoring â†’ Alerting
   - Create Policy

2. **ì¡°ê±´ ì„¤ì •**
   - Resource Type: Cloud Function
   - Metric: executions/count
   - Filter: status != "ok"

3. **ì•Œë¦¼ ì±„ë„ ì„¤ì •**
   - Email ë“±ë¡

## ğŸ”§ ì„¤ì • ë³€ê²½

### ë³´ê´€ ê¸°ê°„ ë³€ê²½

```bash
# 60ì¼ë¡œ ë³€ê²½
gcloud scheduler jobs update pubsub cleanup-old-news-job \
  --location=asia-northeast3 \
  --message-body='{"retention_days": 60}'
```

### ì‹¤í–‰ ì£¼ê¸° ë³€ê²½

```bash
# ë§¤ì£¼ ì‹¤í–‰ìœ¼ë¡œ ë³€ê²½ (ì¼ìš”ì¼ 03:00)
gcloud scheduler jobs update pubsub cleanup-old-news-job \
  --location=asia-northeast3 \
  --schedule="0 3 * * 0"
```

### ë©”ëª¨ë¦¬/íƒ€ì„ì•„ì›ƒ ë³€ê²½

```bash
gcloud functions deploy cleanup-old-news \
  --gen2 \
  --region=asia-northeast3 \
  --memory=512MB \
  --timeout=600s \
  --update-env-vars GOOGLE_CLOUD_PROJECT=YOUR_PROJECT_ID
```

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ: Functionì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ

**í™•ì¸ ì‚¬í•­:**
1. Scheduler Jobì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
   ```bash
   gcloud scheduler jobs describe cleanup-old-news-job \
     --location=asia-northeast3
   ```

2. Pub/Sub Topicì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
   ```bash
   gcloud pubsub topics list
   ```

3. Functionì´ ë°°í¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
   ```bash
   gcloud functions list --gen2 --region=asia-northeast3
   ```

### ë¬¸ì œ: ê¶Œí•œ ì—ëŸ¬ (Permission Denied)

**í•´ê²° ë°©ë²•:**
Cloud Functionì˜ Service Accountì— Firestore ê¶Œí•œ ë¶€ì—¬

```bash
# Functionì˜ Service Account í™•ì¸
gcloud functions describe cleanup-old-news \
  --region=asia-northeast3 \
  --gen2 \
  --format="value(serviceConfig.serviceAccountEmail)"

# Firestore ê¶Œí•œ ë¶€ì—¬
gcloud projects add-iam-policy-binding YOUR_PROJECT_ID \
  --member="serviceAccount:SERVICE_ACCOUNT_EMAIL" \
  --role="roles/datastore.user"
```

### ë¬¸ì œ: íƒ€ì„ì•„ì›ƒ ë°œìƒ

**í•´ê²° ë°©ë²•:**
íƒ€ì„ì•„ì›ƒ ì‹œê°„ ì¦ê°€ ë˜ëŠ” ë°°ì¹˜ í¬ê¸° ì¡°ì •

```bash
# íƒ€ì„ì•„ì›ƒì„ 10ë¶„ìœ¼ë¡œ ì¦ê°€
gcloud functions deploy cleanup-old-news \
  --gen2 \
  --region=asia-northeast3 \
  --timeout=600s
```

### ë¬¸ì œ: created_at í•„ë“œê°€ ì—†ëŠ” ë¬¸ì„œ

**í•´ê²° ë°©ë²•:**
main.pyì—ì„œ í•„ë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë¡œì§ ì¶”ê°€

```python
# ê¸°ì¡´ ì¿¼ë¦¬ ëŒ€ì‹ 
for doc in summaries_ref.stream():
    data = doc.to_dict()
    if 'created_at' not in data:
        logger.warning(f"Document {doc.id} has no created_at field, skipping")
        continue

    created_at = data['created_at']
    if created_at < cutoff_iso:
        batch.delete(doc.reference)
```

## ğŸ’¡ ìµœì í™” íŒ

### 1. ì¸ë±ìŠ¤ ìƒì„±

Firestoreì—ì„œ `created_at` í•„ë“œì— ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ë©´ ì¿¼ë¦¬ ì„±ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤.

**ìë™ ìƒì„±:**
- ì²« ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ìƒì„± ìš”ì²­ ë©”ì‹œì§€ê°€ ë¡œê·¸ì— í‘œì‹œë¨
- ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ì¸ë±ìŠ¤ ìƒì„±

**ìˆ˜ë™ ìƒì„±:**
1. GCP Console â†’ Firestore â†’ Indexes
2. Create Index
   - Collection: summaries
   - Field: created_at (Ascending)

### 2. ë°°ì¹˜ í¬ê¸° ì¡°ì •

ì‚¬ìš©ì ìˆ˜ê°€ ë§¤ìš° ë§ì€ ê²½ìš°:

```python
# ë°°ì¹˜ í¬ê¸°ë¥¼ 500 â†’ 100ìœ¼ë¡œ ì¤„ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½
if batch_count >= 100:
    batch.commit()
    batch = db.batch()
    batch_count = 0
```

### 3. ë³‘ë ¬ ì²˜ë¦¬ (ê³ ê¸‰)

ì‚¬ìš©ìê°€ 1,000ëª… ì´ìƒì¸ ê²½ìš°, ë³‘ë ¬ ì²˜ë¦¬ ê³ ë ¤:
- Cloud Tasksë¡œ ì‚¬ìš©ìë³„ ì‘ì—… ë¶„ì‚°
- ì—¬ëŸ¬ Function ì¸ìŠ¤í„´ìŠ¤ê°€ ë™ì‹œì— ì²˜ë¦¬

## ğŸ“ˆ ì˜ˆìƒ ë¹„ìš©

### ì‚¬ìš©ì 100ëª… ê¸°ì¤€

| í•­ëª© | ì‚¬ì–‘ | ì›”ê°„ ë¹„ìš© |
|------|------|----------|
| Cloud Function | 1íšŒ ì‹¤í–‰, 30ì´ˆ, 256MB | $0.00 (ë¬´ë£Œ) |
| Pub/Sub | ë©”ì‹œì§€ 1ê°œ | $0.00 (ë¬´ë£Œ) |
| Cloud Scheduler | Job 1ê°œ | $0.10 |
| Firestore ì½ê¸° | ~100 documents | $0.00 (ë¬´ë£Œ) |
| Firestore ì‚­ì œ | ~1,000 documents | $0.00 (ë¬´ë£Œ) |
| **ì´ ë¹„ìš©** | | **$0.10/ì›”** |

**ì°¸ê³ :**
- Cloud Functions ë¬´ë£Œ í• ë‹¹ëŸ‰: ì›” 2ë°±ë§Œ í˜¸ì¶œ
- Firestore ë¬´ë£Œ í• ë‹¹ëŸ‰: ì¼ 50,000 ì½ê¸°, 20,000 ì“°ê¸°

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ë°°í¬ ì „ í™•ì¸ì‚¬í•­:

- [ ] `cleanup_function/` ë””ë ‰í† ë¦¬ ìƒì„±
- [ ] `main.py` ì‘ì„± ì™„ë£Œ
- [ ] `requirements.txt` ì‘ì„± ì™„ë£Œ
- [ ] `.gcloudignore` ì‘ì„± ì™„ë£Œ
- [ ] GCP í”„ë¡œì íŠ¸ ID í™•ì¸
- [ ] Pub/Sub Topic ìƒì„±
- [ ] Cloud Function ë°°í¬ ì„±ê³µ
- [ ] Cloud Scheduler Job ìƒì„±
- [ ] ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ë¡œê·¸ í™•ì¸
- [ ] ì•Œë¦¼ ì„¤ì • (ì„ íƒì‚¬í•­)

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [ê°œìš” ë¬¸ì„œ](./cleanup-automation-overview.md)
- [êµ¬í˜„ ë°©ì‹ ë¹„êµ](./cleanup-implementation-comparison.md)
- [Cloud Functions ê³µì‹ ë¬¸ì„œ](https://cloud.google.com/functions/docs)
- [Cloud Scheduler ê³µì‹ ë¬¸ì„œ](https://cloud.google.com/scheduler/docs)

## ğŸ”„ ë¡¤ë°± ë°©ë²•

ë¬¸ì œê°€ ë°œìƒí•œ ê²½ìš°:

```bash
# Cloud Function ì‚­ì œ
gcloud functions delete cleanup-old-news \
  --region=asia-northeast3 \
  --gen2

# Scheduler Job ì‚­ì œ
gcloud scheduler jobs delete cleanup-old-news-job \
  --location=asia-northeast3

# Pub/Sub Topic ì‚­ì œ
gcloud pubsub topics delete cleanup-old-news-topic
```

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ë©´:
1. ë¡œê·¸ í™•ì¸ (`gcloud functions logs read`)
2. íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì„¹ì…˜ ì°¸ì¡°
3. GCP Support ë¬¸ì˜
